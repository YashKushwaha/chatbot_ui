{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2826b52a-5c93-4378-a4e3-3d8d81d57b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import Memory\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8800748-ae9b-4255-a29c-816c42ee4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = \"qwen3:14b\"\n",
    "model = 'qwen3:14b'\n",
    "tokenizer_model = \"Qwen/Qwen3-14B\"\n",
    "context_window = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b91c55-916d-480d-98dd-8c54a5d0c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=model,\n",
    "    request_timeout=120.0,\n",
    "    thinking=True,\n",
    "    context_window=context_window,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2271b865-7aa8-4a48-8d7c-33972ebf350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b49354e-4c5c-4f66-b2d3-0e61eb5d5f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SimpleChatEngine.__init__() missing 3 required positional arguments: 'llm', 'memory', and 'prefix_messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chat_engine \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleChatEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SimpleChatEngine.__init__() missing 3 required positional arguments: 'llm', 'memory', and 'prefix_messages'"
     ]
    }
   ],
   "source": [
    "# Intialize without anything to see what are the mandatory inputs for creating chat engine\n",
    "chat_engine = SimpleChatEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4716dd61-4b54-4ea9-8a1a-721ac7e0726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASSISTANT', 'CHATBOT', 'DEVELOPER', 'FUNCTION', 'MODEL', 'SYSTEM', 'TOOL', 'USER', '__class__', '__doc__', '__members__', '__module__']\n"
     ]
    }
   ],
   "source": [
    "print(dir(MessageRole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1769c805-db7f-4ef4-8201-9c10963ed5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory.from_defaults(token_limit=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef2de0c7-c8f9-4d12-8fe2-76ae24ea0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = ChatMessage(content=\"You are an expert system.\", role=MessageRole.SYSTEM)\n",
    "prefix_messages = [system_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee9acecb-5495-4a3a-a994-f33b36aeced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = SimpleChatEngine(llm=llm, memory=memory, prefix_messages=prefix_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9200b5b-4edb-4954-921d-3867b1f18e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"Hello! I'm Qwen, a large language model developed by Alibaba Cloud. I can help you with a wide range of tasks, such as answering questions, creating content, and having conversations. How can I assist you today?\", sources=[], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = chat_engine.chat(message='Hi, What is your name ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "355bdbe8-63b1-4dee-a1cf-07695b93ee48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Hi, What is your name ?')]),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': None, 'thinking': 'Okay, the user asked, \"Hi, What is your name?\" I need to respond appropriately. Let me think about how to approach this.\\n\\nFirst, the user is introducing themselves and asking for my name. Since I\\'m an AI, I should mention my name and maybe a bit about my purpose. But I should keep it friendly and concise.\\n\\nI should start with a greeting to match their \"Hi.\" Then state my name, which is Qwen. Next, explain that I\\'m a large language model developed by Alibaba Cloud. It\\'s good to mention my capabilities like answering questions, creating content, and having conversations. Also, include that I can help with various tasks. Finally, invite them to ask questions or share ideas. Keep the tone positive and helpful. Let me structure that into a response.\\n'}, blocks=[TextBlock(block_type='text', text=\"Hello! I'm Qwen, a large language model developed by Alibaba Cloud. I can help you with a wide range of tasks, such as answering questions, creating content, and having conversations. How can I assist you today?\")])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e35a2ea-165d-4c35-8168-01295e72b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(message='What does Qwen mean?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c073535-1d35-4b2f-9d2f-1a87593cc4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Hi, What is your name ?')]),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': None, 'thinking': 'Okay, the user asked, \"Hi, What is your name?\" I need to respond appropriately. Let me think about how to approach this.\\n\\nFirst, the user is introducing themselves and asking for my name. Since I\\'m an AI, I should mention my name and maybe a bit about my purpose. But I should keep it friendly and concise.\\n\\nI should start with a greeting to match their \"Hi.\" Then state my name, which is Qwen. Next, explain that I\\'m a large language model developed by Alibaba Cloud. It\\'s good to mention my capabilities like answering questions, creating content, and having conversations. Also, include that I can help with various tasks. Finally, invite them to ask questions or share ideas. Keep the tone positive and helpful. Let me structure that into a response.\\n'}, blocks=[TextBlock(block_type='text', text=\"Hello! I'm Qwen, a large language model developed by Alibaba Cloud. I can help you with a wide range of tasks, such as answering questions, creating content, and having conversations. How can I assist you today?\")]),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='What does Qwen mean?')]),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': None, 'thinking': 'Okay, the user is asking what \"Qwen\" means. Let me recall the name\\'s origin. From what I remember, Qwen is derived from \"Question\" and \"Answer,\" which reflects the model\\'s purpose of answering questions and providing information. But I should check if there\\'s more to it. Also, maybe there\\'s a cultural or linguistic significance. The user might be interested in the etymology or the reasoning behind the name. I should explain it clearly, making sure to highlight the key aspects like the combination of question and answer, and perhaps mention that it\\'s a large language model developed by Alibaba Cloud. Need to keep it concise but informative. Let me structure the response: start by stating the meaning, explain the components, and relate it to the model\\'s function. Avoid any technical jargon. Make sure the user feels their question is fully addressed.\\n'}, blocks=[TextBlock(block_type='text', text='The name **Qwen** is derived from the combination of the words **\"Question\"** and **\"Answer\"**, reflecting the model\\'s core purpose of engaging in conversations, answering questions, and providing helpful information. It symbolizes the model\\'s ability to understand and respond to user inquiries effectively. Additionally, **Qwen** is a large language model developed by Alibaba Cloud, designed to assist with a wide range of tasks, from answering questions to creating content, coding, and more. Let me know if you\\'d like further details! ðŸ˜Š')])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183c6d6c-8e45-4e87-b766-c23b7ec24c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Hi, What is your name ?\n",
      "assistant: Hello! I'm Qwen, a large language model developed by Alibaba Cloud. I can help you with a wide range of tasks, such as answering questions, creating content, and having conversations. How can I assist you today?\n",
      "user: What does Qwen mean?\n",
      "assistant: The name **Qwen** is derived from the combination of the words **\"Question\"** and **\"Answer\"**, reflecting the model's core purpose of engaging in conversations, answering questions, and providing helpful information. It symbolizes the model's ability to understand and respond to user inquiries effectively. Additionally, **Qwen** is a large language model developed by Alibaba Cloud, designed to assist with a wide range of tasks, from answering questions to creating content, coding, and more. Let me know if you'd like further details! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "for i in chat_engine.chat_history:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd0571bc-6ffe-4187-a108-3614654912ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chat_engine.stream_chat(message='Can you tell me more about your developer?')\n",
    "dir(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b746e59e-93a9-428c-af87-25455e0a0ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen is developed by **Tongyi Lab**, a research team under **Alibaba Group**. Tongyi Lab is dedicated to advancing large-scale language models, AI technologies, and their applications. Alibaba Group, one of the world's leading technology companies, has a strong focus on innovation in artificial intelligence, cloud computing, and other cutting-edge technologies. \n",
      "\n",
      "Tongyi Lab's work on Qwen reflects Alibaba's commitment to creating powerful, versatile AI models that can assist users in diverse scenarios, from everyday tasks to complex problem-solving. If you'd like, I can share more details about Alibaba Group or Tongyi Lab's other projects! ðŸ˜Š"
     ]
    }
   ],
   "source": [
    "for i in response2.response_gen:\n",
    "    print(i, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83e22084-511e-4fdf-932f-9f525e588051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen is developed by **Tongyi Lab**, a research team under **Alibaba Group**. Tongyi Lab is dedicated to advancing large-scale language models, AI technologies, and their applications. Alibaba Group, one of the world's leading technology companies, has a strong focus on innovation in artificial intelligence, cloud computing, and other cutting-edge technologies. \n",
      "\n",
      "Tongyi Lab's work on Qwen reflects Alibaba's commitment to creating powerful, versatile AI models that can assist users in diverse scenarios, from everyday tasks to complex problem-solving. If you'd like, I can share more details about Alibaba Group or Tongyi Lab's other projects! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "for i in response2.response_gen:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ac6b558-884f-4491-95b4-8ee93ad0c0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__dataclass_fields__',\n",
       " '__dataclass_params__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_init__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ensure_async_setup',\n",
       " 'achat_stream',\n",
       " 'aprint_response_stream',\n",
       " 'aput_in_queue',\n",
       " 'aqueue',\n",
       " 'async_response_gen',\n",
       " 'awrite_response_to_history',\n",
       " 'awrite_response_to_history_task',\n",
       " 'chat_stream',\n",
       " 'exception',\n",
       " 'is_done',\n",
       " 'is_function',\n",
       " 'is_function_false_event',\n",
       " 'is_function_not_none_thread_event',\n",
       " 'is_writing_to_memory',\n",
       " 'new_item_event',\n",
       " 'print_response_stream',\n",
       " 'put_in_queue',\n",
       " 'queue',\n",
       " 'response',\n",
       " 'response_gen',\n",
       " 'set_source_nodes',\n",
       " 'source_nodes',\n",
       " 'sources',\n",
       " 'unformatted_response',\n",
       " 'write_response_to_history']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f267b87-382b-4ccb-8563-ac67f4cb8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in response2.chat_stream:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97cda84c-c41e-40e4-a800-384d0d123412",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'StreamingAgentChatResponse' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response2:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'StreamingAgentChatResponse' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in response2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30e56a48-0c2d-4e37-9aee-83fc6f51e1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_llm',\n",
       " '_memory',\n",
       " '_prefix_messages',\n",
       " 'achat',\n",
       " 'astream_chat',\n",
       " 'callback_manager',\n",
       " 'chat',\n",
       " 'chat_history',\n",
       " 'chat_repl',\n",
       " 'from_defaults',\n",
       " 'reset',\n",
       " 'stream_chat',\n",
       " 'streaming_chat_repl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chat_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e099f230-efe1-432f-8e28-1b4c94332a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_setattr_handlers__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_copy_and_set_values',\n",
       " '_estimate_token_count',\n",
       " '_format_memory_blocks',\n",
       " '_get_memory_blocks_content',\n",
       " '_get_value',\n",
       " '_insert_memory_content',\n",
       " '_iter',\n",
       " '_manage_queue',\n",
       " '_setattr_handler',\n",
       " '_truncate_memory_blocks',\n",
       " 'aget',\n",
       " 'aget_all',\n",
       " 'aput',\n",
       " 'aput_messages',\n",
       " 'areset',\n",
       " 'aset',\n",
       " 'audio_token_size_estimate',\n",
       " 'chat_history_token_ratio',\n",
       " 'class_name',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'custom_model_dump',\n",
       " 'dict',\n",
       " 'from_defaults',\n",
       " 'from_dict',\n",
       " 'from_json',\n",
       " 'from_orm',\n",
       " 'get',\n",
       " 'get_all',\n",
       " 'image_token_size_estimate',\n",
       " 'insert_method',\n",
       " 'json',\n",
       " 'memory_blocks',\n",
       " 'memory_blocks_template',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'put',\n",
       " 'put_messages',\n",
       " 'reset',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'session_id',\n",
       " 'set',\n",
       " 'sql_store',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'token_flush_size',\n",
       " 'token_limit',\n",
       " 'tokenizer_fn',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_memory']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chat_engine._memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f746511-e1d8-4f0d-9b48-5e57d603784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_limit': 2000,\n",
       " 'token_flush_size': 1400,\n",
       " 'chat_history_token_ratio': 0.7,\n",
       " 'memory_blocks': [],\n",
       " 'memory_blocks_template': RichPromptTemplate(metadata={}, template_vars=['memory_blocks'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template_str='\\n<memory>\\n{% for (block_name, block_content) in memory_blocks %}\\n<{{ block_name }}>\\n  {% for block in block_content %}\\n    {% if block.block_type == \"text\" %}\\n{{ block.text }}\\n    {% elif block.block_type == \"image\" %}\\n      {% if block.url %}\\n        {{ (block.url | string) | image }}\\n      {% elif block.path %}\\n        {{ (block.path | string) | image }}\\n      {% endif %}\\n    {% elif block.block_type == \"audio\" %}\\n      {% if block.url %}\\n        {{ (block.url | string) | audio }}\\n      {% elif block.path %}\\n        {{ (block.path | string) | audio }}\\n      {% endif %}\\n    {% endif %}\\n  {% endfor %}\\n</{{ block_name }}>\\n{% endfor %}\\n</memory>\\n'),\n",
       " 'insert_method': <InsertMethod.SYSTEM: 'system'>,\n",
       " 'image_token_size_estimate': 256,\n",
       " 'audio_token_size_estimate': 256,\n",
       " 'tokenizer_fn': functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'),\n",
       " 'sql_store': SQLAlchemyChatStore(table_name='llama_index_memory', async_database_uri='sqlite+aiosqlite:///:memory:'),\n",
       " 'session_id': '658e0d28-ec4f-4780-80b7-ad1510aff9ed'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine._memory.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "943e758a-25a7-48f5-abe4-d4735258a877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine._memory.memory_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebb5b80b-04ec-4daa-8654-c5cbb44a9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history =chat_engine._memory.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a601db1-92ec-4e49-84cc-e23dd16d5e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Hi, What is your name ?')]),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': None, 'thinking': 'Okay, the user asked, \"Hi, What is your name?\" I need to respond appropriately. Let me think about how to approach this.\\n\\nFirst, the user is introducing themselves and asking for my name. Since I\\'m an AI, I should mention my name and maybe a bit about my purpose. But I should keep it friendly and concise.\\n\\nI should start with a greeting to match their \"Hi.\" Then state my name, which is Qwen. Next, explain that I\\'m a large language model developed by Alibaba Cloud. It\\'s good to mention my capabilities like answering questions, creating content, and having conversations. Also, include that I can help with various tasks. Finally, invite them to ask questions or share ideas. Keep the tone positive and helpful. Let me structure that into a response.\\n'}, blocks=[TextBlock(block_type='text', text=\"Hello! I'm Qwen, a large language model developed by Alibaba Cloud. I can help you with a wide range of tasks, such as answering questions, creating content, and having conversations. How can I assist you today?\")]),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='What does Qwen mean?')]),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': None, 'thinking': 'Okay, the user is asking what \"Qwen\" means. Let me recall the name\\'s origin. From what I remember, Qwen is derived from \"Question\" and \"Answer,\" which reflects the model\\'s purpose of answering questions and providing information. But I should check if there\\'s more to it. Also, maybe there\\'s a cultural or linguistic significance. The user might be interested in the etymology or the reasoning behind the name. I should explain it clearly, making sure to highlight the key aspects like the combination of question and answer, and perhaps mention that it\\'s a large language model developed by Alibaba Cloud. Need to keep it concise but informative. Let me structure the response: start by stating the meaning, explain the components, and relate it to the model\\'s function. Avoid any technical jargon. Make sure the user feels their question is fully addressed.\\n'}, blocks=[TextBlock(block_type='text', text='The name **Qwen** is derived from the combination of the words **\"Question\"** and **\"Answer\"**, reflecting the model\\'s core purpose of engaging in conversations, answering questions, and providing helpful information. It symbolizes the model\\'s ability to understand and respond to user inquiries effectively. Additionally, **Qwen** is a large language model developed by Alibaba Cloud, designed to assist with a wide range of tasks, from answering questions to creating content, coding, and more. Let me know if you\\'d like further details! ðŸ˜Š')]),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Can you tell me more about your developer?')]),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': [], 'thinking': \"Okay, the user asked about the developer of Qwen. I need to provide information about Alibaba Cloud and Tongyi Lab.\\n\\nFirst, I should mention that Alibaba Cloud is part of Alibaba Group and is a leading cloud computing company. Then, introduce Tongyi Lab as the research team behind Qwen. Highlight their focus areas like natural language processing and AI.\\n\\nAlso, mention the broader context of Alibaba Group's involvement in AI and technology. Make sure to keep the information clear and concise, avoiding any technical jargon. Check if there are any key points I might have missed, like the timeline or other projects by the lab. Ensure the response is friendly and invites further questions.\\n\"}, blocks=[TextBlock(block_type='text', text=\"Qwen is developed by **Tongyi Lab**, a research team under **Alibaba Group**. Tongyi Lab is dedicated to advancing large-scale language models, AI technologies, and their applications. Alibaba Group, one of the world's leading technology companies, has a strong focus on innovation in artificial intelligence, cloud computing, and other cutting-edge technologies. \\n\\nTongyi Lab's work on Qwen reflects Alibaba's commitment to creating powerful, versatile AI models that can assist users in diverse scenarios, from everyday tasks to complex problem-solving. If you'd like, I can share more details about Alibaba Group or Tongyi Lab's other projects! ðŸ˜Š\")])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7da186f2-a5eb-4df0-af34-022b69eacf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm Qwen, a large language model developed by Alibaba Cloud. I can help you with a wide range of tasks, such as answering questions, creating content, and having conversations. How can I assist you today?\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bcc8a-3a50-4b20-ad19-0cf790a2b8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
