
# **Reusable LLM UI Project + chat bot using llama index**

This project had following learning objectives -
- Build **reusable front-end UI** that can work with any Large Language Model (LLM) backend.
- Implement chat streaming in back end and front end so that user start to see tokens generated by the LLM in real time rather than waiting for LLM to finish response generation.
- Add memory to the LLM so that it can work as chat bot.
- Explore capabilities available in llama index for building chat bot and other general capabilities (vector store, embedding model etc).
- Currently 4 chat engine classes available in llama index have been implemented
  - SimpleChatEngine - Creates a simple chat bot using LLM & Memory/chat buffer, doesn't make use of a knowledge base
  - ContextChatEngine - Uses LLM, Chat Buffer & vector store. Performs retrieval based on user query, and converts it into context for LLM call
  - CondenseQuestionChatEngine - Uses conversation history and user message to generate a modified query for retrieval.
  - CondensePlusContextChatEngine - combines the functionality of ContextChatEngine & CondenseQuestionChatEngine

- Project uses [squad_v2 dataset](https://huggingface.co/datasets/rajpurkar/squad_v2) for building its knowledge database 
- [ChromaDB offline client](https://docs.trychroma.com/docs/run-chroma/persistent-client) used to store embeddings
- [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) is used as the embedding model
- [MLflow](https://docs.llamaindex.ai/en/stable/examples/observability/MLflow/) used for tracing & debugging
---

## **Project Structure**

The UI is organized into two main components:

- **Front End**  
  Contains Jinja templates for rendering HTML, along with associated CSS and JavaScript files.

- **Back End**  
  FastAPI application that defines API endpoints and serves the front-end templates.
---

- **Note books**  
  - Contains Jupyter notebooks to test Memory module of llama index. This memory module is required to convert a LLM into chatbot.
  - Apart from this Self discover agent has been tested in the notebooks. 

---
- **src**
  Placeholder for bulk of the project logic and creating reusable assets that can be reused across projects

---

## **LLM Integration**

The project uses the `llama-index` framework to define and interact with LLMs. Currently, two LLM integrations are implemented:

- **Ollama**  
  Supports any LLM served locally via Ollama.
- **AWS Bedrock**  
  Connects to LLMs hosted on AWS Bedrock. The demo utilizes the `nova-lite` models.
---

## **Front-End Features**

- ChatGPT-style conversational UI with:
  - Input box (editable `div`) for entering text.  
    *(Supports images and files, though currently only text processing is implemented.)*  
  - Scrollable area for displaying chat history.
  - Sidebar for additional controls or information.

- **Markdown Parsing**  
  LLM responses are rendered using the `marked` JavaScript library for proper Markdown formatting.

- **Code Highlighting**  
  Code snippets in LLM responses are highlighted using `highlight.js`.

---

**Future Development**
- Currently a dark theme has been applied to UI, more effort is needed to align it with modern UI/UX practices
- Have the option to switch between Dark mode & Light Mode. This is easily doable however it would require selecting a color theme to look presentable
- Code clean up and refactoring - This code was created to learn and test certain features and not for putting into production. Thus code base has become little messy.
